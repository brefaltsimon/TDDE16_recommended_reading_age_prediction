{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to recommended age classification\n",
    "This is a project where I try to classify the recommended reading age for children stories based on their descriptions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import spacy # Used for lemmatization & stop word removal\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # Used to tokenize thte words into sequences of integers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # Used to get the same length of all samples after tokenized\n",
    "from sklearn.model_selection import train_test_split # Sklearn has a way to split train and test data which is easy to use\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"children_stories.Csv\", encoding='ISO-8859-1')\n",
    "# df # uncomment to look at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Was it just another game of hide and seek? No. It was not. First she fell into a deep, dark hole in the ground and then they found a treasure. Did it end there? No! It did not. Read more about this thrilling adventure of Sally and friends in this free illustrated kidsâ\\x80\\x99 book. The fun never ends when Sallyâ\\x80\\x99s around! '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What a description can look like\n",
    "df[\"desc\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the unique age categories in order to group them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age ',\n",
       " 'Age  0-3',\n",
       " 'Age 0+',\n",
       " 'Age 0-2',\n",
       " 'Age 0-3',\n",
       " 'Age 0-4',\n",
       " 'Age 0-5',\n",
       " 'Age 0-6',\n",
       " 'Age 1+',\n",
       " 'Age 1-2',\n",
       " 'Age 1-3',\n",
       " 'Age 1-4',\n",
       " 'Age 1-5',\n",
       " 'Age 1-6',\n",
       " 'Age 10+',\n",
       " 'Age 10-14',\n",
       " 'Age 11+',\n",
       " 'Age 11-14',\n",
       " 'Age 11-15',\n",
       " 'Age 12+',\n",
       " 'Age 13+',\n",
       " 'Age 2+',\n",
       " 'Age 2-4',\n",
       " 'Age 2-5',\n",
       " 'Age 2-6',\n",
       " 'Age 2-7',\n",
       " 'Age 2-9',\n",
       " 'Age 3+',\n",
       " 'Age 3-4',\n",
       " 'Age 3-5',\n",
       " 'Age 3-6',\n",
       " 'Age 3-7',\n",
       " 'Age 4+',\n",
       " 'Age 4-11',\n",
       " 'Age 4-5',\n",
       " 'Age 4-6',\n",
       " 'Age 4-7',\n",
       " 'Age 4-8',\n",
       " 'Age 5+',\n",
       " 'Age 5-8',\n",
       " 'Age 5-9',\n",
       " 'Age 6+',\n",
       " 'Age 6-11',\n",
       " 'Age 6-8',\n",
       " 'Age 6-9',\n",
       " 'Age 6months+',\n",
       " 'Age 7+',\n",
       " 'Age 7-10',\n",
       " 'Age 7-11',\n",
       " 'Age 7-12',\n",
       " 'Age 7-9',\n",
       " 'Age 8+',\n",
       " 'Age 8-11',\n",
       " 'Age 8-12',\n",
       " 'Age 9+',\n",
       " 'Age 9-11',\n",
       " 'Age 9-12',\n",
       " 'Age 9-13',\n",
       " 'Age 9-14']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(df['cats'].unique())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now we are only interested in the recommended reading age since that is what we are going to predict\n",
    "we create the labels by getting unique age categories\n",
    "There is one entry that has no age so we remove that one. (it only says \"Age \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age 9+          0.074766\n",
       "Age 3+          0.074766\n",
       "Age 7+          0.063084\n",
       "Age 8+          0.060748\n",
       "Age 10+         0.060748\n",
       "Age 6+          0.049065\n",
       "Age 2-9         0.046729\n",
       "Age 4+          0.046729\n",
       "Age 11+         0.044393\n",
       "Age 5+          0.039720\n",
       "Age 0-4         0.037383\n",
       "Age 0+          0.030374\n",
       "Age 2+          0.028037\n",
       "Age 12+         0.028037\n",
       "Age 0-3         0.025701\n",
       "Age 2-6         0.023364\n",
       "Age 3-6         0.021028\n",
       "Age 2-5         0.021028\n",
       "Age 0-5         0.018692\n",
       "Age 3-5         0.016355\n",
       "Age 1-3         0.014019\n",
       "Age 1-5         0.011682\n",
       "Age 3-7         0.011682\n",
       "Age 1-4         0.009346\n",
       "Age 8-12        0.009346\n",
       "Age 7-11        0.009346\n",
       "Age 13+         0.007009\n",
       "Age 6-11        0.007009\n",
       "Age 4-8         0.007009\n",
       "Age 9-11        0.007009\n",
       "Age 5-8         0.007009\n",
       "Age 4-6         0.007009\n",
       "Age 1+          0.004673\n",
       "Age 4-7         0.004673\n",
       "Age 6-8         0.004673\n",
       "Age 9-13        0.004673\n",
       "Age 7-10        0.004673\n",
       "Age 5-9         0.004673\n",
       "Age 9-12        0.004673\n",
       "Age 7-9         0.004673\n",
       "Age 0-2         0.004673\n",
       "Age 9-14        0.002336\n",
       "Age 10-14       0.002336\n",
       "Age 8-11        0.002336\n",
       "Age 11-14       0.002336\n",
       "Age 2-4         0.002336\n",
       "Age 6-9         0.002336\n",
       "Age 7-12        0.002336\n",
       "Age 6months+    0.002336\n",
       "Age 4-5         0.002336\n",
       "Age 1-2         0.002336\n",
       "Age 4-11        0.002336\n",
       "Age 0-6         0.002336\n",
       "Age 1-6         0.002336\n",
       "Age 3-4         0.002336\n",
       "Age 2-7         0.002336\n",
       "Age  0-3        0.002336\n",
       "Age 11-15       0.002336\n",
       "Name: cats, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(df.query(\"cats == 'Age '\").index, axis=0).reset_index(drop=True)\n",
    "df['cats'].value_counts() / len(df['cats']) # See the percentage in the split of categories\n",
    "# The split is quite low for each of the current categories so we should group them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10    0.147196\n",
      "3     0.126168\n",
      "2     0.123832\n",
      "0     0.123832\n",
      "9     0.093458\n",
      "7     0.084112\n",
      "8     0.072430\n",
      "4     0.070093\n",
      "6     0.063084\n",
      "5     0.051402\n",
      "1     0.044393\n",
      "Name: cats, dtype: float64\n",
      "0       2\n",
      "1       2\n",
      "2       2\n",
      "3       2\n",
      "4       2\n",
      "       ..\n",
      "423    10\n",
      "424     8\n",
      "425     9\n",
      "426     9\n",
      "427     7\n",
      "Name: cats, Length: 428, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def group(entry):\n",
    "    zero = ['Age  0-3', 'Age 0+', 'Age 0-2', 'Age 0-3', 'Age 0-4', 'Age 0-5', 'Age 0-6', 'Age 6months+']\n",
    "    one = ['Age 1+', 'Age 1-2', 'Age 1-3', 'Age 1-4', 'Age 1-5', 'Age 1-6']\n",
    "    two = ['Age 2+', 'Age 2-4', 'Age 2-5', 'Age 2-6', 'Age 2-7', 'Age 2-9']\n",
    "    three = [ 'Age 3+', 'Age 3-4', 'Age 3-5', 'Age 3-6', 'Age 3-7']\n",
    "    four = [ 'Age 4+', 'Age 4-11', 'Age 4-5', 'Age 4-6', 'Age 4-7', 'Age 4-8']\n",
    "    five = ['Age 5+', 'Age 5-8', 'Age 5-9']\n",
    "    six = ['Age 6+', 'Age 6-11', 'Age 6-8', 'Age 6-9']\n",
    "    seven = [ 'Age 7+', 'Age 7-10', 'Age 7-11', 'Age 7-12', 'Age 7-9']\n",
    "    eight = ['Age 8+', 'Age 8-11', 'Age 8-12']\n",
    "    nine = ['Age 9+', 'Age 9-11', 'Age 9-12', 'Age 9-13', 'Age 9-14']\n",
    "    ten = [ 'Age 10+', 'Age 10-14', 'Age 11+', 'Age 11-14', 'Age 11-15', 'Age 12+', 'Age 13+']\n",
    "    return 0 if entry in zero else 1 if entry in one else 2 if entry in two else 3 if entry in three else 4 if entry in four else 5 if entry in five else 6 if entry in six else 7 if entry in seven else 8 if entry in eight else 9 if entry in nine else 10\n",
    "df['cats'] = df['cats'].apply(group)\n",
    "print(df['cats'].value_counts() / len(df['cats']))\n",
    "print(df['cats'])\n",
    "# Still pretty bad for some, I would like 4 categories to not have them too small, we can get the starting age as the label\n",
    "# we could probably group 0-2, 3-5, 6-8, 9+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.292056\n",
      "3    0.247664\n",
      "9    0.240654\n",
      "6    0.219626\n",
      "Name: cats, dtype: float64\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "423    9\n",
      "424    6\n",
      "425    9\n",
      "426    9\n",
      "427    6\n",
      "Name: cats, Length: 428, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Now we get a more even split with 5 categories, they are named after their starting age respectively\n",
    "def group2(entry):\n",
    "    return 0 if entry < 3 else 3 if entry < 6 else 6 if entry < 9 else 9\n",
    "\n",
    "df['cats'] = df['cats'].apply(group2)\n",
    "print(df['cats'].value_counts() / len(df['cats']))\n",
    "print(df['cats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a one-hot representation for a keras categorical crossentropy loss so lets make df['cats'] to a one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cats'] = pd.get_dummies(df['cats']).to_numpy().tolist()\n",
    "# We get the following split\n",
    "# 3 = [0, 1, 0, 0] - 29.2%\n",
    "# 0 = [1, 0, 0, 0] - 24.8%\n",
    "# 9 = [0, 0, 0, 1] - 24.1%\n",
    "# 6 = [0, 0, 1, 0] - 22%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0]    0.292056\n",
      "[0, 1, 0, 0]    0.247664\n",
      "[0, 0, 0, 1]    0.240654\n",
      "[0, 0, 1, 0]    0.219626\n",
      "Name: cats, dtype: float64\n",
      "0      [1, 0, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "423    [0, 0, 0, 1]\n",
      "424    [0, 0, 1, 0]\n",
      "425    [0, 0, 0, 1]\n",
      "426    [0, 0, 0, 1]\n",
      "427    [0, 0, 1, 0]\n",
      "Name: cats, Length: 428, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['cats'].value_counts() / len(df['cats']))\n",
    "print(df['cats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our labels fixed we preprocess the descriptions using SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner']) # Used for stop word removal, nummerical removal and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    # replace .lemma_ with .orht_ to skip lemmatization\n",
    "    text = ' '.join([token.lemma_ for token in doc if not token.is_stop and token.lemma_.isalpha()]) # we still want a string returned so we join on ws before returning\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create copies so we dont have to work with the entire dataframe any longer since we unly use 2 of its 3 columns and we also apply the pre-processing to the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = df['desc'].copy().apply(preprocess)\n",
    "labels_unprocessed = df['cats'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the labels are converted into a numpy ndarray which we need them to be in order to send as input to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [1, 0, 0, 0]\n",
       "1      [1, 0, 0, 0]\n",
       "2      [1, 0, 0, 0]\n",
       "3      [1, 0, 0, 0]\n",
       "4      [1, 0, 0, 0]\n",
       "           ...     \n",
       "423    [0, 0, 0, 1]\n",
       "424    [0, 0, 1, 0]\n",
       "425    [0, 0, 0, 1]\n",
       "426    [0, 0, 0, 1]\n",
       "427    [0, 0, 1, 0]\n",
       "Name: cats, Length: 428, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_unprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels need to be of the right type in order to be passed to the network, an ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.vstack(labels_unprocessed.values)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use keras Tokenizer to turn our words in to a integer sequence with a unitue integer for each word is represented through a unique integer.\n",
    "In case we missed some filterings for puncuations and special character when using spacy the tokenizer will remove them. It will also split the string on whitespaces and form words.\n",
    "We are fitting the tokenizer on the descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(descriptions)\n",
    "descriptions = tokenizer.texts_to_sequences(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get this from the length of the tokenizer's word_index, and add 1 for the zero padding.\n",
    "We also get the longest description and pad the descriptions to this length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab len: 5320\n",
      "Max len: 144\n"
     ]
    }
   ],
   "source": [
    "vocab_len = len(tokenizer.word_index) + 1\n",
    "max_desc_length = np.max(list(map(lambda desc: len(desc), descriptions)))\n",
    "descriptions = pad_sequences(descriptions, maxlen=max_desc_length, padding='post')\n",
    "print(\"Vocab len:\", vocab_len)\n",
    "print(\"Max len:\", max_desc_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428, 144)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 209,  210,  349, ...,    0,    0,    0],\n",
       "       [  21,  109,   12, ...,    0,    0,    0],\n",
       "       [   7, 1314,   23, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 302,   23, 1506, ...,    0,    0,    0],\n",
       "       [ 190,   90,  537, ...,    0,    0,    0],\n",
       "       [   9,   45, 5312, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(descriptions.shape) #Shape\n",
    "descriptions # We see all padded now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use sklearn's train_test_split() function to split into train and test sets. Random state 50 so these results can be reproduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions_train, descriptions_test, labels_train, labels_test = train_test_split(descriptions, labels, train_size=0.8, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can try to augment the training data by duplicating it to get more samples, did not give any improvements tho\n",
    "# labels_train = np.vstack((labels_train, labels_train))\n",
    "# descriptions_train = np.vstack((descriptions_train, descriptions_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptions is our input and with the padding all have the same size, \"max_desc_length\"\n",
    "\n",
    "The embedding layer is used to embed the descriptions to a high-dimensional vectro space\n",
    "This allow learning representations for words, rather than manually creating them.\n",
    "\n",
    "With a GRU layer we capture time-dependent information. So we pass the descriptions through one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.Input(shape=(max_desc_length,), name=\"descriptions\")\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_len,\n",
    "    output_dim=128,\n",
    "    input_length=max_desc_length,\n",
    "    name=\"embedding\"\n",
    ")(input)\n",
    "\n",
    "gru_layer = tf.keras.layers.GRU(\n",
    "    units=256,\n",
    "    return_sequences=True,\n",
    "    name=\"gru_layer\"\n",
    ")(embedding_layer)\n",
    "\n",
    "desc_flatten = tf.keras.layers.Flatten(name=\"flatten\")(gru_layer)\n",
    "\n",
    "output = tf.keras.layers.Dense(len(labels[0]), activation='sigmoid', name=\"output\")(desc_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "descriptions (InputLayer)    [(None, 144)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 144, 256)          1361920   \n",
      "_________________________________________________________________\n",
      "gru_layer (GRU)              (None, 144, 128)          148224    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 73732     \n",
      "=================================================================\n",
      "Total params: 1,583,876\n",
      "Trainable params: 1,583,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=input, outputs=output)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the network with NAdam as an optimizer and categorical_crossentropy loss since we use multiple categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 144) <dtype: 'float32'>\n",
      "(None, 4) <dtype: 'float32'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model.compile(\n",
    "    optimizer='nadam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "[print(i.shape, i.dtype) for i in model.inputs]\n",
    "[print(o.shape, o.dtype) for o in model.outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 6s 348ms/step - loss: 1.3897 - accuracy: 0.2784 - auc: 0.5146 - val_loss: 1.3124 - val_accuracy: 0.5072 - val_auc: 0.7099\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 3s 287ms/step - loss: 1.2670 - accuracy: 0.5018 - auc: 0.7345 - val_loss: 1.1782 - val_accuracy: 0.4928 - val_auc: 0.7577\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 1.0922 - accuracy: 0.6557 - auc: 0.8159 - val_loss: 1.0964 - val_accuracy: 0.5797 - val_auc: 0.8075\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 3s 300ms/step - loss: 0.6959 - accuracy: 0.8755 - auc: 0.9107 - val_loss: 1.0257 - val_accuracy: 0.5942 - val_auc: 0.8026\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 264ms/step - loss: 0.4341 - accuracy: 0.8938 - auc: 0.9413 - val_loss: 0.8989 - val_accuracy: 0.6667 - val_auc: 0.8407\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 257ms/step - loss: 0.1642 - accuracy: 0.9744 - auc: 0.9867 - val_loss: 0.8863 - val_accuracy: 0.6232 - val_auc: 0.8379\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 3s 310ms/step - loss: 0.0562 - accuracy: 1.0000 - auc: 0.9949 - val_loss: 0.8834 - val_accuracy: 0.6522 - val_auc: 0.8493\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 3s 299ms/step - loss: 0.0200 - accuracy: 1.0000 - auc: 0.9933 - val_loss: 0.9690 - val_accuracy: 0.6667 - val_auc: 0.8498\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 0.0062 - accuracy: 1.0000 - auc: 0.9825 - val_loss: 1.0356 - val_accuracy: 0.6667 - val_auc: 0.8490\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 264ms/step - loss: 0.0023 - accuracy: 1.0000 - auc: 0.9720 - val_loss: 1.0938 - val_accuracy: 0.6667 - val_auc: 0.8480\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    descriptions_train,\n",
    "    labels_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3) # when there is no improvement we should terminate early\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 58ms/step - loss: 1.1842 - accuracy: 0.5814 - auc: 0.8195\n",
      "Accuracy: 0.5813953280448914\n",
      "ROC AUC: 0.8194745182991028\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(descriptions_test, labels_test)\n",
    "\n",
    "print(\"Accuracy:\", results[1])\n",
    "print(\"ROC AUC:\", results[2])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ceee0ac25c751b1098a4fb73f2440c883a17b1f4b57a8a66be014cd396dd854c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
